{
    "abstract": "Random reshuffling techniques are prevalent in large-scale applications, such as training neural networks. While the convergence and acceleration effects of random reshuffling-type methods are fairly well understood in the smooth setting, much less studies seem available in the nonsmooth case. In this work, we design a new normal map-based proximal random reshuffling (norm-PRR) method for nonsmooth nonconvex finite-sum problems. We show that norm-PRR achieves the iteration complexity ${\\cal O}(n^{-1/3}T^{-2/3})$ where $n$ denotes the number of component functions $f(\\cdot,i)$ and $T$ counts the total number of iterations. This improves the currently known complexity bounds for this class of problems by a factor of $n^{-1/3}$ in terms of the number of gradient evaluations.  Additionally, we prove that norm-PRR converges linearly under the (global) Polyak-\u0141ojasiewicz condition and in the interpolation setting. We further complement these non-asymptotic results and provide an in-depth analysis of the asymptotic properties of norm-PRR. Specifically, under the (local) Kurdyka-\u0141ojasiewicz  inequality, the whole sequence of iterates generated by norm-PRR is shown to converge to a single stationary point. Moreover, we derive last-iterate convergence rates that can match those in the smooth, strongly convex setting. Finally, numerical experiments are performed on nonconvex classification tasks to illustrate the efficiency of the proposed approach.",
    "authors": [
        "Junwen Qiu",
        "Xiao Li",
        "Andre Milzarek"
    ],
    "emails": [
        "jwqiu@nus.edu.sg",
        "lixiao@cuhk.edu.cn",
        "andremilzarek@cuhk.edu.cn"
    ],
    "id": "24-0891",
    "issue": 191,
    "pages": [
        1,
        46
    ],
    "title": "A New Random Reshuffling Method for Nonsmooth Nonconvex Finite-sum Optimization",
    "volume": 26,
    "year": 2025
}