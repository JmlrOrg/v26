{
    "abstract": "It is widely known that the error analysis for deep learning involves approximation, statistical, and optimization errors. However, it is challenging to combine them together due to overparameterization. In this paper, we address this gap by providing a comprehensive error analysis of the Deep Ritz Method (DRM). Specifically, we investigate a foundational question in the theoretical analysis of DRM under the overparameterized regime: given a target precision level, how can one determine the appropriate number of training samples, the key architectural parameters of the neural networks, the step size for the projected gradient descent optimization procedure, and the requisite number of iterations, such that the output of the gradient descent process closely approximates the true solution of the underlying partial differential equation to the specified precision?",
    "authors": [
        "Yuling Jiao",
        "Ruoxuan Li",
        "Peiying Wu",
        "Jerry Zhijian Yang",
        "Pingwen Zhang"
    ],
    "emails": [
        "yulingjiaomath@whu.edu.cn",
        "ruoxuanli.math@whu.edu.cn",
        "peiyingwu@whu.edu.cn",
        "zjyang.math@whu.edu.cn",
        "pwzhang@whu.edu.cn"
    ],
    "id": "24-1258",
    "issue": 115,
    "pages": [
        1,
        76
    ],
    "title": "DRM Revisited: A Complete Error Analysis",
    "volume": 26,
    "year": 2025
}